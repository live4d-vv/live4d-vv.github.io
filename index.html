<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <meta name="description" content="Live4D Project is designed for low-cost, real-time, streamable volumetric capture.">
  <meta name="keywords" content="Live4D">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Live4D: A Real-time Capture System for Streamable Volumetric Video</title>


  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Live4D: A Real-time Capture System for Streamable Volumetric Video</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="" target="_blank">Yifeng Zhou</a><sup>*</sup>,
              </span>
              <span class="author-block">
                <a href="" target="_blank">Shuheng Wang</a><sup>*</sup>,
              </span>
              <span class="author-block">
                <a href="" target="_blank">Wenfa Li</a><sup>*</sup>,
              </span>
              <span class="author-block">
                <a href="" target="_blank">Chao Zhang</a><sup>*</sup>,
              </span>
              <span class="author-block">
                Li Rao,
              </span>
              <span class="author-block">
                Pu Cheng,
              </span>
              <span class="author-block">
                Yi Xu,
              </span>
            </br>
              <span class="author-block">
                Jinle Ke,
              </span>
              <span class="author-block">
                Wenduo Feng,
              </span>
              <span class="author-block">
                Wen Zhou,
              </span>
              <span class="author-block">
                Hao Xu,
              </span>
              <span class="author-block">
                Yukang Gao,
              </span>
              <span class="author-block">
                Yang Ding,
              </span>
              <span class="author-block">
                Weixuan Tang,
              </span>
              <span class="author-block">
                Shaohui Jiao
              </span>
            </div>
          <hr>
          <div class="is-size-5 publication-authors">
            <span class="author-block">ByteDance, China<br>SIGGRAPH Asia 2023 Techinical Communications<br></span>
            <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution.</small></span><br>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">


                    <!-- ArXiv abstract Link -->
                    <span class="link-block">
                      <a href="https://drive.google.com/file/d/1ncHB7zhwy-P8Iu8plQhWDCXI0YzYVccV/view?usp=drive_link" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Paper</span>
                    </a>
                  </span>

                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://dl.acm.org/doi/10.1145/3610543.3626178" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Short Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <span class="link-block">
                      <a href="https://dl.acm.org/action/downloadSupplement?doi=10.1145%2F3610543.3626178&file=supplementary.zip" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span>

                  <!-- Data link -->
                  <span class="link-block">
                    <a href="" target=""
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fa fa-database"></i>
                    </span>
                    <span>Data</span>
                  </a>
                </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser image-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="static/images/teaser.png" alt="Live4D Show Case"/>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Volumetric video holds promise for virtual and augmented reality (VR/AR) applications but faces challenges in interactive scenarios due to high hardware costs, complex processing and substantial data streams. In this paper, we introduce Live4D, a cost-effective, real-time volumetric video generation and streaming system using an RGB-only camera setup. We propose a novel deep implicit surface reconstruction algorithm, that combined neural signed distance field with observed truncated signed distance field to generate the watertight meshes with low latency. Moreover, we achieve a robust non-rigid tracking method that provides temporal stability to the meshes while resisting tracking failure cases. Experimental results show that Live4D achieves a performance of 24fps using mid-range graphic cards and exhibits an end-to-end latency of 95ms. The system enables live streaming of volumetric video within a 20Mbps bandwidth requirement, positioning Live4D as a promising solution for real-time 3D vision content creation in the growing VR/AR industry.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Pipeline image-->
<section class="section hero is-small">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Pipeline</h2>
    <div class="hero-body">
      <img src="static/images/pipeline.png" alt="Live4D Show Case"/>
      <h2 class="subtitle has-text-justified">
      </h2>
    </div>
  </div>
<!-- End pipeline image -->

<!-- Paper abstract -->
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
        <div class="content has-text-justified">
          <p>
            Overview of the Live4D system. We directly take synchronized multi-view raw images as the system input. After ISP and stereo-rectification of calibrated RGB streams, several lightweight networks are employed to generate RGB-D frames, incorporating ROI information. These data are transmitted to the reconstruction server. It first performs TSDF fusion and applies the proposed volumetric completion method to achieve watertight implicit surface reconstruction. Simultaneously, historical frames are integrated and preserved in the key frame, finally fused to current data volume to ensure temporal stability of the signed distance field. Subsequently, mesh is generated through Marching Cubes, and further mesh processing includes geometry refinement and face reduction to improve quality and streaming efficiency. Ultimately, the mesh undergoes texture mapping, encoding and delivery to individual clients for rendering purposes.
          </p>
          <br>
        </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->




<!-- Youtube video -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container is-max-desktop content">
      <!-- Paper video. -->
      <h2 class="title is-3">Video</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video">
            <!-- Youtube embed code here -->
            <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End youtube video -->


<!-- Dataset -->
<section class="section" id="samples">

  <div class="container is-max-desktop">
    <h2 class="title is-3">Data</h2>
    <!-- <div class="hero-body">
    </div> -->
    <div class="column is-three-fifths">
    </div>
  </div>

  <div class="container is-max-desktop content">
    <div class="content has-text-justified">
      <p>
        We publish a portion of the data and its corresponding reconstruction samples here for potential future research. [coming soon]
        <!-- The data provided is collected using our experimental devices. 
        The accuracy of depth estimation significantly impacts the quality of the final reconstructed meshes. 
        Hence, we will provide depth maps of varying qualities along with their respective reconstruction results to ensure thorough verification. 
        For detailed information on data formats, please refer to the readme.md file in the data folder. -->
      </p>
      <br>
    </div>
  </div>
</section>
<!--End BibTex citation -->




<!--BibTex citation -->
  <section class="section hero is-light" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@inproceedings{zhou2023live4d,
        author = {Zhou, Yifeng and Wang, Shuheng and Li, Wenfa and Zhang, Chao and Rao, Li and Cheng, Pu and Xu, Yi and Ke, Jinle and Feng, Wenduo and Zhou, Wen and Xu, Hao and Gao, Yukang and Ding, Yang and Tang, Weixuan and Jiao, Shaohui},
        title = {Live4D: A Real-time Capture System for Streamable Volumetric Video},
        pages={1--4},
        booktitle = {SIGGRAPH Asia 2023 Technical Communications},
        year = {2023},
        }</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
